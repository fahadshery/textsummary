% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/word_freqs_by_category.R
\name{word_freqs_by_category}
\alias{word_freqs_by_category}
\title{Plot or get top n word frequencies using English grammar in a collection of text documents and compare by categories variable}
\usage{
word_freqs_by_category(df, text_col, categories_col,
  number_of_words_to_plot = 10, plot = TRUE, grammer_phrase = "NOUN",
  word_type = lemma)
}
\arguments{
\item{df}{a data.frame or a tibble/tribble}

\item{text_col}{the name of the text column within df}

\item{categories_col}{the name of the factor/categorical column to calculate the words in each category or level}

\item{number_of_words_to_plot}{how many words/terms to plot within each level of categories_col? Plots Top 10 words in each category by default}

\item{plot}{return a ggplot2? or get a tokenised/lemmatised df created by udpipe model. TRUE by default}

\item{grammer_phrase}{what to filter on? Possible options include all the universal parts of speech tags such as noun, verb, adj, pron, aux, num etc. more info here: \url{https://polyglot.readthedocs.io/en/latest/POS.html}}

\item{word_type}{tokens or lemmas to plot}
}
\description{
Tokenising, Lemmatising, Tagging and Dependency Parsing of raw text using udpipe as a backend. Counts the number of words by each level in a categorical variable. Either plots or returns the tokenised df
}
\examples{
\dontrun{
data("text_data")
word_freqs_by_category(verbatim,text_col = text, categories_col = NPS_RATING)
word_freqs_by_category(verbatim,text_col = text, categories_col = NPS_RATING, word_type = token)
word_freqs_by_category(verbatim,text,Qtr,number_of_words_to_plot = 20)
}
}
\seealso{
\code{\link[textSummary]{word_frequencies_by_category}}
}
